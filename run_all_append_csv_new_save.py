# -*- coding: utf-8 -*-
"""
ChatGPTä½œæˆå•é¡Œã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‚’èµ°æŸ»ã—ã€
(å¹´åº¦, æ—¥ä»˜, ç§‘ç›®, Qç•ªå·) ã®4ç‚¹ã‚­ãƒ¼ã§ã€Œå•é¡Œã€ã¨ã€Œè§£ç­”ã€ã‚’ãƒšã‚¢ãƒªãƒ³ã‚°ã€‚
æ—¢å­˜CSVã‚’ä¸Šæ›¸ãã›ãšã€æ–°è¦ãƒ‡ãƒ¼ã‚¿ã®ã¿è¿½è¨˜ï¼ˆAppendï¼‰ã€‚
Google Drive ã®ãƒªãƒ³ã‚¯ã¯ã€ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ã§æ¤œç´¢ã—ã¦è£œå®Œï¼ˆåŒæ„ç”»é¢ãªã—ï¼‰ã€‚
"""

import os
import re
import csv
import unicodedata
from datetime import datetime
from collections import defaultdict
from typing import Dict, Tuple, Optional, List, Set

# ====== å›ºå®šãƒ‘ã‚¹ï¼ˆã‚ãªãŸã®ç’°å¢ƒã«åˆã‚ã›ã¦æ—¢ã«ä½¿ç”¨ã—ã¦ã„ã‚‹å€¤ï¼‰ ======
# â˜… ä¿®æ­£ï¼šç’°å¢ƒå¤‰æ•° ROOT_DIR ã‚’å„ªå…ˆï¼ˆæ—¢å®šã¯å¾“æ¥ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ï¼‰
ROOT_DIR = os.environ.get(
    "ROOT_DIR",
    "/Users/odaakihisa/Library/CloudStorage/GoogleDrive-radioheadsyrup16g@gmail.com/ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–/è¨ºæ–­å£«è©¦é¨“/ä¸€æ¬¡è©¦é¨“/å•é¡Œãƒ»æ¼”ç¿’/chat gptä½œæˆå•é¡Œ"
)

LOG_DIR  = os.environ.get("LOG_DIR", "/Users/odaakihisa/Library/CloudStorage/GoogleDrive-radioheadsyrup16g@gmail.com/ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–/è¨ºæ–­å£«è©¦é¨“/ä¸€æ¬¡è©¦é¨“/_logs")
CSV_OUT  = os.environ.get("CSV_PATH", "/Users/odaakihisa/Documents/Notion_Auto/automation/data/ChatGPT_Merge_master.csv")
BAK_PATH = CSV_OUT + ".bak"

# Drive ãƒ«ãƒ¼ãƒˆï¼ˆã‚ãªãŸãŒæ¸¡ã—ãŸãƒ•ã‚©ãƒ«ãƒ€IDï¼‰
DRIVE_ROOT_ID = "1XL-9dP0ToNj5MgAMCEPqGH52rUYSciWK"

# ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONï¼ˆã‚ãªãŸãŒä½¿ã£ã¦ã„ã‚‹å®Ÿãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®šï¼‰
SERVICE_ACCOUNT_FILE = os.environ.get(
    "SERVICE_ACCOUNT_FILE",
    "/Users/odaakihisa/Documents/Notion_Auto/automation/notionauto-474307-50e14130c274.json"
)

# ====== æ¤œç´¢ãƒ«ãƒ¼ãƒ« ======
ROLE_BY_FOLDER = {"å•é¡Œ": "problem", "ç­”æ¡ˆè§£èª¬": "answer"}
SUBJ_MAP = {"è²¡å‹™": "è²¡å‹™ä¼šè¨ˆ", "è²¡å‹™ä¼šè¨ˆ": "è²¡å‹™ä¼šè¨ˆ", "çµŒæ¸ˆ": "çµŒæ¸ˆå­¦", "çµŒæ¸ˆå­¦": "çµŒæ¸ˆå­¦","æ³•å‹™": "æ³•å‹™","çµŒå–¶æ³•å‹™": "æ³•å‹™",  "æƒ…å ±": "æƒ…å ±","çµŒå–¶æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ ": "æƒ…å ±"}

Q_RE    = re.compile(r"(?:^|_)Q(\d{1,2})(?:_|$)", re.IGNORECASE)
DATE_RE = re.compile(r"(\d{4})_(\d{4})")

# ====== Driveï¼ˆã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ã®ã¿ã€‚OAuthåŒæ„ç”»é¢ãªã—ï¼‰ ======
from google.oauth2 import service_account
from googleapiclient.discovery import build

SCOPES = ["https://www.googleapis.com/auth/drive.metadata.readonly"]

def build_drive_service():
    if not os.path.exists(SERVICE_ACCOUNT_FILE):
        raise FileNotFoundError(f"[FATAL] ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒç„¡ã„: {SERVICE_ACCOUNT_FILE}")
    creds = service_account.Credentials.from_service_account_file(
        SERVICE_ACCOUNT_FILE, scopes=SCOPES
    )
    svc = build("drive", "v3", credentials=creds, cache_discovery=False)
    print("âœ… Drive(Service Account) OKï¼ˆåŒæ„ç”»é¢ãªã—ï¼‰")
    return svc

def nfc(s: str) -> str:
    return unicodedata.normalize("NFC", s or "")

def norm_subject(name: str) -> Optional[str]:
    if not name: return None
    return SUBJ_MAP.get(name.strip(), name.strip())

def parse_meta_from_path(path: str) -> Optional[Tuple[str, str, str]]:
    m = DATE_RE.search(path)
    if not m: return None
    year, mmdd = m.group(1), m.group(2)
    q = "Q??"
    mq = Q_RE.search(os.path.basename(path))
    if mq: q = f"Q{int(mq.group(1)):02d}"
    return (year, mmdd, q)

def guess_role_by_path(path: str) -> Optional[str]:
    for p in path.split(os.sep):
        if p in ROLE_BY_FOLDER: return ROLE_BY_FOLDER[p]
    return None

def build_title_from_problem_path(problem_path: str) -> str:
    base = os.path.splitext(os.path.basename(problem_path))[0]
    return base

def walk_files(root: str):
    for dirpath, _, filenames in os.walk(root):
        for fn in filenames:
            if fn.lower().endswith(".txt"):
                yield os.path.join(dirpath, fn)

def collect_and_pair_files(root_dir: str):
    print("â–¶ ãƒ•ã‚¡ã‚¤ãƒ«åé›†é–‹å§‹...")
    items: Dict[Tuple[str, str, str, str], Dict[str, str]] = defaultdict(dict)
    for path in walk_files(root_dir):
        role = guess_role_by_path(path)
        if role not in ("problem", "answer"): continue
        rel = os.path.relpath(path, root_dir)
        parts = rel.split(os.sep)
        subj = norm_subject(parts[0] if parts else "")
        if not subj: continue
        meta = parse_meta_from_path(path)
        if not meta: continue
        year, mmdd, qno = meta
        key = (year, mmdd, subj, qno)
        items[key].setdefault("problem", "")
        items[key].setdefault("answer", "")
        items[key][role] = path
    print(f"â–¶ åé›†å®Œäº†: {len(items)}ä»¶")
    return items

def make_uid(year: str, mmdd: str, subj: str, qno: str) -> str:
    return f"{year}-{mmdd}-{subj}-{qno}"

def read_existing_uids(csv_path: str) -> Set[str]:
    uids = set()
    if not os.path.exists(csv_path): return uids
    with open(csv_path, "r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for row in reader:
            uid = row.get("å¤–éƒ¨UID")
            if not uid:
                y, d, s, q = row.get("å¹´åº¦",""), row.get("æ—¥ä»˜",""), row.get("ç§‘ç›®",""), row.get("Qç•ªå·","")
                if y and d and s and q:
                    uid = make_uid(y, d, s, q)
            if uid:
                uids.add(uid)
    return uids

def resolve_drive_url_by_local_path(drive, drive_root_id, local_path, root_dir):
    """ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ™ãƒ¼ã‚¹åã§Driveæ¤œç´¢ â†’ è¦ªãƒ•ã‚©ãƒ«ãƒ€åä¸€è‡´ã‚¹ã‚³ã‚¢ã§æœ€é©1ä»¶ â†’ webViewLink"""
    if not local_path:
        return ""
    base = os.path.basename(local_path)

    res = drive.files().list(
        q=f"name = '{base}' and trashed = false",
        fields="files(id,name,parents,webViewLink)",
        pageSize=50,
        includeItemsFromAllDrives=True,
        supportsAllDrives=True,
    ).execute()
    files = res.get("files", [])

    if not files:
        return ""

    rel = os.path.relpath(local_path, root_dir)
    local_dirs = [nfc(x) for x in rel.split(os.sep)[:-1]]

    parent_cache = {}
    def get_first_parent_name(file):
        parents = file.get("parents") or []
        if not parents:
            return ""
        pid = parents[0]
        if pid in parent_cache:
            return parent_cache[pid]
        meta = drive.files().get(
            fileId=pid,
            fields="id,name,parents",
            supportsAllDrives=True
        ).execute()
        parent_cache[pid] = meta.get("name","")
        return parent_cache[pid]

    best, best_score = None, -1
    for f in files:
        pname = nfc(get_first_parent_name(f))
        score = 0
        if local_dirs:
            last_local = local_dirs[-1]
            if pname == last_local:
                score += 2
            elif pname.lower() == last_local.lower():
                score += 1
        if score > best_score:
            best, best_score = f, score

    if not best:
        return ""
    return best.get("webViewLink") or f"https://drive.google.com/open?id={best['id']}&usp=drive_fs"

# ===â˜… ã“ã“ã‹ã‚‰è¿½åŠ ï¼ˆæ”¹è¡Œä¿è¨¼é–¢æ•°ï¼‰â˜…===
def ensure_trailing_newline(path: str):
    """æ—¢å­˜CSVã®æœ«å°¾ã«æ”¹è¡ŒãŒç„¡ã‘ã‚Œã°è£œã†"""
    if not os.path.exists(path) or os.path.getsize(path) == 0:
        return
    with open(path, "rb") as f:
        f.seek(-1, os.SEEK_END)
        last = f.read(1)
    if last not in (b"\n", b"\r"):
        with open(path, "ab") as f:
            f.write(b"\n")
# ===â˜… ã“ã“ã¾ã§è¿½åŠ â˜…===

def process_and_output_csv(items, csv_out, log_dir):
    os.makedirs(os.path.dirname(csv_out), exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)
    nowstamp = datetime.now().strftime("%Y%m%d_%H%M")
    log_path = os.path.join(log_dir, f"build_log_{nowstamp}.txt")

    headers = [
        "å¹´åº¦", "æ—¥ä»˜", "Qç•ªå·", "ç§‘ç›®", "ã‚¿ã‚¤ãƒˆãƒ«",
        "å•é¡Œ", "è§£ç­”è§£èª¬", "ç¨®åˆ¥", "å•é¡Œã®ç¨®é¡",
        "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹(å•é¡Œ)", "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹(è§£ç­”)", "å¤–éƒ¨UID",
    ]

    existing_uids = read_existing_uids(csv_out)
    print(f"â–¶ æ—¢å­˜UIDæ•°: {len(existing_uids)}")

    drive = build_drive_service()

    new_rows: List[List[str]] = []
    for (year, mmdd, subj, qno), rec in sorted(items.items()):
        uid = make_uid(year, mmdd, subj, qno)
        if uid in existing_uids:
            continue  # è¿½è¨˜ã®ã¿

        prob_path = rec.get("problem", "")
        ans_path  = rec.get("answer",  "")
        title = build_title_from_problem_path(prob_path) if prob_path else ""
        type1, kind = "å•é¡Œ", "ChatGPTå•é¡Œ"

        # LinkFillã¨åŒè¶£æ—¨ã®ãƒªãƒ³ã‚¯è£œå®Œï¼ˆDriveæ¤œç´¢ï¼‰
        prob_url = resolve_drive_url_by_local_path(drive, DRIVE_ROOT_ID, prob_path, ROOT_DIR)
        ans_url  = resolve_drive_url_by_local_path(drive, DRIVE_ROOT_ID,  ans_path, ROOT_DIR)

        new_rows.append([
            year, mmdd, qno, subj, title,
            prob_url, ans_url, type1, kind,
            prob_path, ans_path, uid
        ])

    if new_rows:
        write_header = not os.path.exists(csv_out) or os.path.getsize(csv_out) == 0

        # æ”¹è¡Œä¿è¨¼ï¼ˆä¸Šæ›¸ãã¯ã—ãªã„ï¼‰
        ensure_trailing_newline(csv_out)

        # è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ï¼ˆä¸Šæ›¸ãç¦æ­¢ï¼‰
        with open(csv_out, "a", encoding="utf-8-sig", newline="") as f:
            w = csv.writer(f)
            if write_header:
                w.writerow(headers)
            w.writerows(new_rows)
        print(f"âœ… {len(new_rows)}ä»¶ã‚’è¿½è¨˜ã—ã¾ã—ãŸ â†’ {csv_out}")
    else:
        print("â–¶ æ–°è¦ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆè¿½è¨˜ã‚¼ãƒ­ï¼‰")

    with open(log_path, "w", encoding="utf-8") as lg:
        lg.write(f"{datetime.now().isoformat()} ã«å®Œäº†\n")
    print(f"ğŸ“ ãƒ­ã‚°: {log_path}")
    print("â–¶ END")

def main():
    items = collect_and_pair_files(ROOT_DIR)
    process_and_output_csv(items, CSV_OUT, LOG_DIR)

if __name__ == "__main__":
    main()
